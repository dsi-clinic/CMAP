{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import system utilities and set module path\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# Import PyTorch utilities\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import dataset handling\n",
    "from torchgeo.datasets import NAIP, stack_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project configs and data handlers\n",
    "from configs import config\n",
    "from data.kc import KaneCounty\n",
    "from data.sampler import BalancedRandomBatchGeoSampler\n",
    "\n",
    "# Import visualization and utility tools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from matplotlib.colors import ListedColormap\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NAIP dataset\n",
    "naip_dataset = NAIP(\"/net/projects/cmap/data/KC-images\")\n",
    "\n",
    "# Define path to shape file\n",
    "shape_path = Path(config.KC_SHAPE_ROOT) / config.KC_SHAPE_FILENAME\n",
    "\n",
    "# Define dataset configuration using config parameters\n",
    "dataset_config = (\n",
    "    config.KC_LAYER,\n",
    "    config.KC_LABELS, \n",
    "    config.PATCH_SIZE,\n",
    "    naip_dataset.crs,\n",
    "    naip_dataset.res,\n",
    ")\n",
    "\n",
    "# Initialize Kane County dataset\n",
    "kc_dataset = KaneCounty(shape_path, dataset_config)\n",
    "\n",
    "# Merge NAIP dataset with Kane County dataset\n",
    "train_dataset = naip_dataset & kc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a balanced random batch sampler for training\n",
    "train_sampler = BalancedRandomBatchGeoSampler(\n",
    "    config={\n",
    "        \"dataset\": train_dataset,\n",
    "        \"size\": config.PATCH_SIZE,  \n",
    "        \"batch_size\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "# DataLoader for visualizing training samples\n",
    "plot_dataloader = DataLoader(\n",
    "    dataset=train_dataset,  \n",
    "    batch_sampler=train_sampler,  \n",
    "    collate_fn=stack_samples,  \n",
    "    num_workers=config.NUM_WORKERS,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataloader and print the shapes of image and mask tensors,\n",
    "MAX_BATCHES = 2\n",
    "EXPECTED_DIM = 3\n",
    "SINGLE_CHANNEL = 1\n",
    "RGB_CHANNELS = 3\n",
    "\n",
    "for batch, sample in enumerate(plot_dataloader):\n",
    "    print(sample[\"image\"].shape, sample[\"mask\"].shape)\n",
    "    if batch > MAX_BATCHES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create a custom colormap from kc_dataset.colors ---\n",
    "# Sort the keys so that the colormap is consistent\n",
    "sorted_keys = sorted(kc_dataset.colors.keys())\n",
    "# Normalize the colors (RGB only) to [0,1]\n",
    "color_list = [tuple(np.array(kc_dataset.colors[k][:3]) / 255.0) for k in sorted_keys]\n",
    "custom_cmap = ListedColormap(color_list)\n",
    "\n",
    "# --- Extract one sample from the dataloader ---\n",
    "sample = next(iter(plot_dataloader))\n",
    "img_tensor = sample[\"image\"][0]  # shape: (channels, height, width)\n",
    "mask_tensor = sample[\"mask\"][0]  # shape: (height, width) or (1, height, width)\n",
    "\n",
    "if mask_tensor.dim() == EXPECTED_DIM and mask_tensor.shape[0] == SINGLE_CHANNEL:\n",
    "    mask_tensor = mask_tensor.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the first 3 channels for RGB visualization\n",
    "img_rgb = (\n",
    "    img_tensor[:RGB_CHANNELS] if img_tensor.shape[0] >= RGB_CHANNELS else img_tensor\n",
    ")\n",
    "\n",
    "# Rearrange the image to (height, width, channels) and convert to NumPy uint8\n",
    "img_rgb_np = rearrange(img_rgb, \"c h w -> h w c\").cpu().numpy().astype(\"uint8\")\n",
    "# Convert mask to NumPy array for plotting\n",
    "mask_np = mask_tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create two subplots: RGB Image & True Label Mask ---\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# 1. Display RGB Image (No Mask Overlay)\n",
    "axs[0].imshow(img_rgb_np, interpolation=\"none\")\n",
    "axs[0].set_title(\"RGB Image\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "# 2. Display True Label Mask (solid colors, no alpha blending)\n",
    "axs[1].imshow(\n",
    "    mask_np, cmap=custom_cmap, interpolation=\"none\", vmin=0, vmax=len(sorted_keys) - 1\n",
    ")\n",
    "axs[1].set_title(\"True Label Mask\")\n",
    "axs[1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create a legend for the True Label Mask ---\n",
    "legend_handles = []\n",
    "unique_vals_in_mask = set(\n",
    "    np.unique(mask_np)\n",
    ")  # Only include labels that appear in the image\n",
    "\n",
    "for k in sorted_keys:\n",
    "    if k in unique_vals_in_mask:\n",
    "        label_name = kc_dataset.labels_inverse.get(k, str(k))\n",
    "        color = tuple(np.array(kc_dataset.colors[k][:3]) / 255.0)\n",
    "        patch = mpatches.Patch(color=color, label=label_name)\n",
    "        legend_handles.append(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add legend below the True Label Mask (only for present labels)\n",
    "if legend_handles:\n",
    "    fig.legend(\n",
    "        handles=legend_handles, loc=\"lower center\", ncol=4, bbox_to_anchor=(0.5, -0.1)\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the module path is correctly added\n",
    "sys.path.append(\"/home/gregoryc25/CMAP/segment_anything_source_code\")\n",
    "\n",
    "# Import necessary components\n",
    "from segment_anything.build_sam import sam_model_registry\n",
    "from segment_anything.predictor import SamPredictor\n",
    "\n",
    "# Define checkpoint path\n",
    "home_dir = Path.home()\n",
    "sam_checkpoint = home_dir / \"CMAP/segment_anything_source_code/sam_vit_h.pth\"\n",
    "\n",
    "# Ensure the checkpoint file exists\n",
    "if not sam_checkpoint.exists():\n",
    "    raise FileNotFoundError(f\"Checkpoint file not found: {sam_checkpoint}\")\n",
    "\n",
    "# Load the model\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=str(sam_checkpoint))  # Ensure the path is a string\n",
    "predictor = SamPredictor(sam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get unique values from the mask (excluding background=0)\n",
    "unique_vals = torch.unique(mask_tensor)\n",
    "valid_labels = unique_vals[unique_vals > 0]  # Exclude background (0)\n",
    "\n",
    "if len(valid_labels) == 0:\n",
    "    raise ValueError(\"No valid foreground labels found!\")\n",
    "\n",
    "# 2) Pick a random label from the valid set\n",
    "random_label_idx = torch.randint(0, len(valid_labels), (1,)).item()\n",
    "chosen_label = valid_labels[random_label_idx].item()\n",
    "\n",
    "# 3) Gather all pixel coordinates of the chosen label\n",
    "ys, xs = torch.where(mask_tensor == chosen_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(xs) > 0 and len(ys) > 0:\n",
    "    # 4) Pick a random point within that label\n",
    "    random_index = torch.randint(0, len(xs), (1,)).item()\n",
    "    seed_x = xs[random_index].item()\n",
    "    seed_y = ys[random_index].item()\n",
    "\n",
    "    print(f\"Selected label: {chosen_label}\")\n",
    "    print(f\"Seed coordinate: (x={seed_x}, y={seed_y})\")\n",
    "\n",
    "    # Sanity check\n",
    "    if mask_tensor[seed_y, seed_x] != chosen_label:\n",
    "        raise ValueError(\"Seed point not inside the chosen label!\")\n",
    "else:\n",
    "    raise ValueError(\"No valid pixel found for chosen label!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we're using the same stored seed point\n",
    "print(f\"Using  segmentation seed coordinate: (x={seed_x}, y={seed_y})\")\n",
    "\n",
    "# Create the seed coordinate array in the expected shape (1, 2)\n",
    "seed_coordinate = np.array([[seed_x, seed_y]])\n",
    "seed_label = np.array([1])  # Positive prompt\n",
    "\n",
    "# Set the image before predicting\n",
    "predictor.set_image(img_rgb_np)\n",
    "\n",
    "# --- Call the SAM predictor with the **same seed** ---\n",
    "masks, scores, logits = predictor.predict(\n",
    "    point_coords=seed_coordinate,\n",
    "    point_labels=seed_label,\n",
    "    multimask_output=False,  # Single best mask\n",
    ")\n",
    "\n",
    "# Select the **highest scoring mask**\n",
    "best_mask = masks[0]\n",
    "best_score = scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create Three Subplots: RGB, True Label Mask, Segmentation Mask ---\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# 1. Display RGB Image with Seed Point\n",
    "axs[0].imshow(img_rgb_np, interpolation=\"none\")\n",
    "axs[0].scatter(seed_x, seed_y, color=\"red\", s=50, marker=\"o\", edgecolors=\"black\")\n",
    "axs[0].set_title(\"RGB Image\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "# 2. Display True Label Mask with Seed Point (Solid Colors)\n",
    "axs[1].imshow(\n",
    "    mask_np, cmap=custom_cmap, interpolation=\"none\", vmin=0, vmax=len(sorted_keys) - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs[1].scatter(seed_x, seed_y, color=\"red\", s=50, marker=\"o\", edgecolors=\"black\")\n",
    "axs[1].set_title(\"True Label Mask\")\n",
    "axs[1].axis(\"off\")\n",
    "\n",
    "# 3. Display Best Segmentation Mask with Seed Point\n",
    "axs[2].imshow(best_mask, cmap=\"gray\", interpolation=\"none\")\n",
    "axs[2].scatter(seed_x, seed_y, color=\"red\", s=50, marker=\"o\", edgecolors=\"black\")\n",
    "axs[2].set_title(f\"Segmentation Mask\\nScore: {best_score:.2f}\")\n",
    "axs[2].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = home_dir / \"CMAP/segment-anything/kc_sam_outputs\"\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generate a unique filename (timestamp-based)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_path = output_folder / f\"segmentation_{timestamp}.png\"\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(output_path, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved segmentation result to: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class & Instance IoU\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils.kc_visualizations_helper import compute_iou_per_class, compute_instance_iou\n",
    "\n",
    "# Instance IoU\n",
    "iou_instance = compute_instance_iou(best_mask, mask_np, chosen_label)\n",
    "print(f\"Instance {chosen_label} IoU: {iou_instance:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
